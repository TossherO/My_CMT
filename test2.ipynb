{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmengine\n",
    "import numpy as np\n",
    "from mmengine.fileio import get\n",
    "from mmdet3d.structures import LiDARInstance3DBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = mmengine.load('./data/JRDB/JRDB_infos_train_small.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['metainfo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(info['data_list']), info['data_list'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['data_list'][0]['images'].keys(), info['data_list'][0]['images']['cam0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['data_list'][0]['lidar_points'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(info['data_list'][0]['instances'][0]), info['data_list'][0]['instances'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_3d = [instance['bbox_3d'] for instance in info['data_list'][0]['instances']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_3d_ = LiDARInstance3DBoxes(bboxes_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_3d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算标签的范围\n",
    "min = np.array([np.inf, np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "max = np.array([-np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf])\n",
    "count = 0\n",
    "for data in info['data_list']:\n",
    "    for instence in data['instances']:\n",
    "        min = np.minimum(min, instence['bbox_3d'][:6])\n",
    "        max = np.maximum(max, instence['bbox_3d'][:6])\n",
    "        count += 1\n",
    "min, max, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 1, 1\n",
    "bbox_3d = info['data_list'][i]['instances'][j]['bbox_3d']\n",
    "bbox = info['data_list'][i]['instances'][j]['bbox']\n",
    "lidar2img = info['data_list'][i]['images']['left']['lidar2img']\n",
    "bbox_3d, bbox, lidar2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = info['data_list'][4]\n",
    "lidar2img = np.array(info['images']['left']['cam2img']) @ np.array(info['images']['left']['lidar2cam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar2img.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import mmengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undisort_image(image, K, D):\n",
    "    h, w = image.shape[:2]\n",
    "    new_K, roi = cv2.getOptimalNewCameraMatrix(K, D, (w, h), 0, (w, h))\n",
    "    undistorted_image = cv2.undistort(image, K, D, None, new_K)\n",
    "    return undistorted_image, new_K\n",
    "\n",
    "data_dir = './data/JRDB/'\n",
    "calibration_dir = \"../jrdb_toolkit/calibration/\"\n",
    "location = 'stlc-111-2019-04-19_0'\n",
    "lidar_config = os.path.join(calibration_dir, \"lidars.yaml\")\n",
    "\n",
    "with open(lidar_config, 'r') as f:\n",
    "    lidar_calib = yaml.safe_load(f)\n",
    "\n",
    "idx = 1500\n",
    "infos = mmengine.load('./data/JRDB/JRDB_infos_train_small.pkl')\n",
    "info = infos['data_list'][idx]\n",
    "\n",
    "# Load pointclouds    \n",
    "lower_pcd = o3d.io.read_point_cloud(\n",
    "    os.path.join(data_dir, info['lidar_points']['lidar_path_lower'])).points\n",
    "upper_pcd = o3d.io.read_point_cloud(\n",
    "    os.path.join(data_dir, info['lidar_points']['lidar_path_upper'])).points\n",
    "# homogenize the points\n",
    "upper_pcd = np.hstack([np.array(upper_pcd), np.ones((len(upper_pcd), 1))])\n",
    "lower_pcd = np.hstack([np.array(lower_pcd), np.ones((len(lower_pcd), 1))])\n",
    "lower2upper = np.array(info[\"lidar_points\"][\"lower2upper\"])\n",
    "###### apply the transformation to the lower lidar ########\n",
    "lower_pcd = np.dot(lower2upper, np.transpose(np.array(lower_pcd)))\n",
    "# merge the pointclouds\n",
    "merged_pcd = np.hstack([np.transpose(np.array(upper_pcd)), lower_pcd]).transpose()\n",
    "bbox_3d = np.array([item['bbox_3d'] for item in info['instances']])\n",
    "print(bbox_3d.shape)\n",
    "\n",
    "# Iterating over specified camera IDs to process and visualize point clouds on undistorted images.\n",
    "for cam_id in [0, 2, 4, 6, 8]:\n",
    "    # Retrieve calibration data for the current camera, including both distorted and undistorted intrinsic matrices.\n",
    "    undistorted_K = np.array(info['images']['cam'+str(cam_id)]['cam2img'])[:3, :3]\n",
    "    undistorted_K = np.hstack([undistorted_K, np.zeros((3, 1))])  # Homogenize the undistorted intrinsic matrix.\n",
    "    distored_K = np.array(info['images']['cam'+str(cam_id)]['distored_K']).reshape(3, 3)\n",
    "    D = np.array(info['images']['cam'+str(cam_id)]['D'])  # Distortion coefficients.\n",
    "\n",
    "    # Compute the transformation matrix from the LiDAR (upper) to the camera coordinate system and project the points.\n",
    "    upper2ego = np.array(info[\"lidar_points\"][\"lidar2ego\"])\n",
    "    ego2cam = np.array(info['images']['cam'+str(cam_id)][\"lidar2cam\"])\n",
    "    pts_ref = ego2cam.dot(upper2ego.dot(merged_pcd.T)).T\n",
    "    pts_ref = undistorted_K.dot(pts_ref.T).T  # Project points using the undistorted intrinsic matrix.\n",
    "    pts_ref = pts_ref[pts_ref[:, 2] > 0]  # Keep only points in front of the camera.\n",
    "    pts_ref = pts_ref[:, :2] / pts_ref[:, 2].reshape(-1, 1)  # Normalize points to the image plane.\n",
    "\n",
    "    # Load the corresponding camera image, undistort it, and plot the projected points on this undistorted image.\n",
    "    image = cv2.imread(os.path.join(data_dir, info['images']['cam'+str(cam_id)]['img_path']))\n",
    "    undistorted_image, _ = undisort_image(image, distored_K, D)  # Undistort the image using its intrinsic matrix and distortion coefficients.\n",
    "\n",
    "    # Draw each point on the undistorted image.\n",
    "    for pts in pts_ref:\n",
    "        x, y = pts\n",
    "        if 0 <= x < undistorted_image.shape[1] and 0 <= y < undistorted_image.shape[0]:\n",
    "            cv2.circle(undistorted_image, (int(x), int(y)), 1, (0, 255, 0), -1)\n",
    "\n",
    "    # 将 bbox_3d 投影到图像上，bbox_3d 的格式是 [x, y, z, l, w, h, yaw]\n",
    "    for bbox in bbox_3d:\n",
    "        x, y, z, l, w, h, ry = bbox\n",
    "        # 3D bounding box corners\n",
    "        corners = np.array([\n",
    "            [l/2, w/2, h/2],\n",
    "            [l/2, w/2, -h/2],\n",
    "            [l/2, -w/2, h/2],\n",
    "            [l/2, -w/2, -h/2],\n",
    "            [-l/2, w/2, h/2],\n",
    "            [-l/2, w/2, -h/2],\n",
    "            [-l/2, -w/2, h/2],\n",
    "            [-l/2, -w/2, -h/2],\n",
    "        ])\n",
    "        # 3D bounding box rotation matrix\n",
    "        R = np.array([\n",
    "            [np.cos(ry), np.sin(ry), 0],\n",
    "            [-np.sin(ry), np.cos(ry), 0],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        t = np.array([x, y, z+h/2])\n",
    "        corners = np.dot(R, corners.T).T + t\n",
    "        corners = np.hstack([corners, np.ones((corners.shape[0], 1))])\n",
    "        corners = undistorted_K.dot(ego2cam.dot(corners.T)).T\n",
    "        # 绘制在图像上的 3D bbox 线条\n",
    "        # for i, j in [(0, 1), (1, 3), (3, 2), (2, 0), (4, 5), (5, 7), (7, 6), (6, 4), (0, 4), (1, 5), (2, 6), (3, 7)]:\n",
    "        #     if corners[i, 2] > 0 and corners[j, 2] > 0:\n",
    "        #         cv2.line(undistorted_image, (int(corners[i, 0]/corners[i, 2]), int(corners[i, 1]/corners[i, 2])),\n",
    "        #                 (int(corners[j, 0]/corners[j, 2]), int(corners[j, 1]/corners[j, 2])), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    # Display the undistorted image with projected points, enhancing visualization for applications like deep learning pipelines.\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cv2.cvtColor(undistorted_image, cv2.COLOR_BGR2RGB))  # Display the image in RGB format.\n",
    "    plt.title(f'Camera {cam_id} Point Cloud Projection on Undistorted Image')\n",
    "    plt.axis('off')  # Hide the axis for a cleaner view.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = mmengine.load('./data/STCrowd/STCrowd_infos_train.pkl')\n",
    "info2 = mmengine.load('./data/kitti/kitti_infos_trainval2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_fusion = mmengine.load('./data/kitti_stc_fusion_infos_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = [0, 0, 0, 0]\n",
    "count2 = [0, 0, 0]\n",
    "difficults = [0, 0, 0]\n",
    "for data in info_fusion['data_list']:\n",
    "    for instance in data['instances']:\n",
    "        count1[instance['occluded']] += 1\n",
    "        difficult = instance['occluded']\n",
    "        dist = np.sqrt(instance['bbox_3d'][0]**2 + instance['bbox_3d'][1]**2)\n",
    "        if dist > 20:\n",
    "            count2[2] += 1\n",
    "            difficult += 2\n",
    "        elif dist > 10:\n",
    "            count2[1] += 1\n",
    "            difficult += 1\n",
    "        else:\n",
    "            count2[0] += 1\n",
    "        difficults[difficult//2] += 1\n",
    "count1, count2, difficults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0, 0, 0]\n",
    "for data in info_fusion['data_list']:\n",
    "    for instance in data['instances']:\n",
    "        count[instance['difficulty']] += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "([32440, 54602, 48117, 54], [66122, 39256, 29835], [57942, 60957, 16314])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(info_fusion['data_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_fusion['metainfo'], info_fusion['data_list'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info2['data_list'][2]['instances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_min = np.array([np.inf, np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "instance_max = np.array([-np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf])\n",
    "count = 0\n",
    "for data in info_fusion['data_list']:\n",
    "    for instance in data['instances']:\n",
    "        instance['bbox_3d'] = np.array(instance['bbox_3d'])\n",
    "        instance_min = np.minimum(instance_min, instance['bbox_3d'][:6])\n",
    "        instance_max = np.maximum(instance_max, instance['bbox_3d'][:6])\n",
    "        # if 0 < instance['bbox_3d'][0] < 36 and -18 < instance['bbox_3d'][1] < 18 and -5 < instance['bbox_3d'][2] < 1:\n",
    "        count += 1\n",
    "            \n",
    "instance_min, instance_max, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_rot = np.random.normal(scale=[1, 2, 3], size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_rot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99929137, -0.00648181,  0.03707754],\n",
       "       [ 0.00571193,  0.99976666,  0.02083254],\n",
       "       [-0.03720392, -0.02060599,  0.99909522]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rotation.from_euler('xyz', noise_rot, degrees=True).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

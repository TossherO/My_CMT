{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, mmengine, mmcv, mmdet, mmdet3d, spconv\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(mmengine.__version__)\n",
    "print(mmcv.__version__)\n",
    "print(mmdet.__version__)\n",
    "print(mmdet3d.__version__)\n",
    "print(spconv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmengine.config import Config, DictAction\n",
    "from mmengine.logging import print_log\n",
    "from mmengine.registry import RUNNERS\n",
    "from mmengine.runner import Runner\n",
    "from mmengine import fileio\n",
    "\n",
    "from mmdet3d.utils import replace_ceph_backend\n",
    "\n",
    "from projects.mmdet3d_plugin.models.detectors import CmtDetector\n",
    "import time\n",
    "from mmengine.structures import InstanceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('projects/configs/fusion/my_cmt_kitti.py')\n",
    "# cfg = Config.fromfile('../mmdetection3d/projects/BEVFusion/configs/my_bevfusion.py')\n",
    "cfg.work_dir = osp.abspath('./work_dirs')\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    data_batch = next(iter(runner.train_dataloader))\n",
    "    data_batch = runner.model.data_preprocessor(data_batch, training=False)\n",
    "    batch_inputs_dict = data_batch['inputs']\n",
    "    batch_data_samples = data_batch['data_samples']\n",
    "    imgs = batch_inputs_dict.get('imgs', None)\n",
    "    points = batch_inputs_dict.get('points', None)\n",
    "    img_metas = [item.metainfo for item in batch_data_samples]\n",
    "    gt_bboxes_3d = [item.get('gt_instances_3d')['bboxes_3d'] for item in batch_data_samples]\n",
    "    gt_labels_3d = [item.get('gt_instances_3d')['labels_3d'] for item in batch_data_samples]\n",
    "\n",
    "    # img_feats = runner.model.extract_img_feat(imgs, img_metas)\n",
    "    # voxels, num_points, coors = runner.model.voxelize(points)\n",
    "    # voxel_features = runner.model.pts_voxel_encoder(voxels, num_points, coors)\n",
    "    # batch_size = coors[-1, 0] + 1\n",
    "    # x1 = runner.model.pts_middle_encoder(voxel_features, coors, batch_size)\n",
    "    # x2 = runner.model.pts_backbone(x1)\n",
    "    # if runner.model.with_pts_neck:\n",
    "    #     x3 = runner.model.pts_neck(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data_batch['inputs']['imgs'][0][0].permute(1, 2, 0).cpu().numpy()\n",
    "img = mmcv.imdenormalize(img, mean=np.array([103.530, 116.280, 123.675]), std=np.array([57.375, 57.120, 58.395]), to_bgr=False)\n",
    "img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = img_metas[0].get('filename')\n",
    "img_bytes = fileio.get(filename, backend_args=None)\n",
    "img = mmcv.imfrombytes(img_bytes, flag='color', backend='cv2')\n",
    "img = img.astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_bboxes_3d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_feats[0].shape, img_feats[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_features.shape, x1.shape, x2[0].shape, x2[1].shape, x3[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程\n",
    "for data_batch in runner.train_dataloader:\n",
    "    data_batch = runner.model.data_preprocessor(data_batch, training=True)\n",
    "    if isinstance(data_batch, dict):\n",
    "        losses = runner.model(**data_batch, mode='loss')\n",
    "    elif isinstance(data_batch, (list, tuple)):\n",
    "        losses = runner.model(*data_batch, mode='loss')\n",
    "    else:\n",
    "        raise TypeError()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch['inputs'], data_batch['data_samples'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证过程\n",
    "for data_batch in runner.val_dataloader:\n",
    "    data_batch = runner.model.data_preprocessor(data_batch, training=False)\n",
    "    if isinstance(data_batch, dict):\n",
    "        outputs = runner.model(**data_batch, mode='predict')\n",
    "    elif isinstance(data_batch, (list, tuple)):\n",
    "        outputs = runner.model(**data_batch, mode='predict')\n",
    "    else:\n",
    "        raise TypeError()\n",
    "    runner.val_evaluator.process(data_samples=outputs, data_batch=data_batch)\n",
    "    break\n",
    "# with torch.no_grad():\n",
    "#     metrics = runner.val_evaluator.evaluate(len(runner.val_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch['inputs']['imgs'][0][:,300:400,300:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "num = 0\n",
    "with torch.no_grad():\n",
    "    for data_batch in runner.val_dataloader:\n",
    "        data_batch = runner.model.data_preprocessor(data_batch, training=False)\n",
    "        if isinstance(data_batch, dict):\n",
    "            outputs = runner.model(**data_batch, mode='predict')\n",
    "        elif isinstance(data_batch, (list, tuple)):\n",
    "            outputs = runner.model(**data_batch, mode='predict')\n",
    "        else:\n",
    "            raise TypeError()\n",
    "        num += 1\n",
    "        if num == 100:\n",
    "            break\n",
    "print(time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "with torch.no_grad():\n",
    "    data_batch_raw = next(iter(runner.val_dataloader))\n",
    "    for _ in range(100):\n",
    "        data_batch = runner.model.data_preprocessor(data_batch_raw, training=False)\n",
    "        if isinstance(data_batch, dict):\n",
    "            outputs = runner.model(**data_batch, mode='predict')\n",
    "        elif isinstance(data_batch, (list, tuple)):\n",
    "            outputs = runner.model(**data_batch, mode='predict')\n",
    "        else:\n",
    "            raise TypeError()\n",
    "print(time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    data_batch = next(iter(runner.val_dataloader))\n",
    "    data_batch = runner.model.data_preprocessor(data_batch, training=False)\n",
    "    batch_inputs_dict = data_batch['inputs']\n",
    "    batch_data_samples = data_batch['data_samples']\n",
    "    imgs = batch_inputs_dict.get('imgs', None)\n",
    "    points = batch_inputs_dict.get('points', None)\n",
    "    img_metas = [item.metainfo for item in batch_data_samples]\n",
    "\n",
    "    time_start = time.time()\n",
    "    for _ in range(100):\n",
    "        img_feats = runner.model.extract_img_feat(imgs, img_metas)\n",
    "    \n",
    "    midedle1 = time.time()\n",
    "    for _ in range(100):\n",
    "        pts_feats = runner.model.extract_pts_feat(points, img_feats, img_metas)\n",
    "\n",
    "    midedle2 = time.time()\n",
    "    for _ in range(100):\n",
    "        outs = runner.model.pts_bbox_head(pts_feats, img_feats, img_metas)\n",
    "\n",
    "    middle3 = time.time()\n",
    "    for _ in range(100):\n",
    "        bbox_list = runner.model.pts_bbox_head.get_bboxes(\n",
    "            outs, img_metas, rescale=False)\n",
    "        \n",
    "        # bbox_results = []\n",
    "        # for bboxes, scores, labels in bbox_list:\n",
    "        #     results = InstanceData()\n",
    "        #     results.bboxes_3d = bboxes.to('cpu')\n",
    "        #     results.scores_3d = scores.cpu()\n",
    "        #     results.labels_3d = labels.cpu()\n",
    "        #     bbox_results.append(results)\n",
    "        # detsamples = runner.model.add_pred_to_datasample(batch_data_samples,\n",
    "        #                                             data_instances_3d = bbox_results,\n",
    "        #                                             data_instances_2d = None)\n",
    "    end = time.time()\n",
    "    print(midedle1 - time_start, midedle2 - midedle1, middle3 - midedle2, end - middle3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

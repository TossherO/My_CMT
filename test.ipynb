{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, mmengine, mmcv, mmdet, mmdet3d, spconv\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(mmengine.__version__)\n",
    "print(mmcv.__version__)\n",
    "print(mmdet.__version__)\n",
    "print(mmdet3d.__version__)\n",
    "print(spconv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "\n",
    "from mmengine.config import Config, DictAction\n",
    "from mmengine.logging import print_log\n",
    "from mmengine.registry import RUNNERS\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "from mmdet3d.utils import replace_ceph_backend\n",
    "\n",
    "from projects.mmdet3d_plugin.models.detectors import CmtDetector\n",
    "import time\n",
    "from mmengine.structures import InstanceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/helloalone/新加卷/ubuntu_anaconda_envs/python38/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/media/helloalone/新加卷/ubuntu_anaconda_envs/python38/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/19 13:20:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1028313016\n",
      "    GPU 0: NVIDIA GeForce RTX 3060\n",
      "    CUDA_HOME: /usr/local/cuda-12.2\n",
      "    NVCC: Cuda compilation tools, release 12.2, V12.2.91\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.1.2\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2a0\n",
      "    OpenCV: 4.5.5\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1028313016\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/19 13:20:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=48, enable=False)\n",
      "backend_args = None\n",
      "class_names = [\n",
      "    'Pedestrian',\n",
      "    'Cyclist',\n",
      "    'Car',\n",
      "]\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False, imports=[\n",
      "        'projects.mmdet3d_plugin',\n",
      "    ])\n",
      "data_root = 'data/kitti/'\n",
      "dataset_type = 'KittiDataset'\n",
      "db_sampler = dict(\n",
      "    backend_args=None,\n",
      "    classes=[\n",
      "        'Pedestrian',\n",
      "        'Cyclist',\n",
      "        'Car',\n",
      "    ],\n",
      "    data_root='data/kitti/',\n",
      "    info_path='data/kitti/kitti_dbinfos_train.pkl',\n",
      "    points_loader=dict(\n",
      "        backend_args=None,\n",
      "        coord_type='LIDAR',\n",
      "        load_dim=4,\n",
      "        type='LoadPointsFromFile',\n",
      "        use_dim=4),\n",
      "    prepare=dict(\n",
      "        filter_by_difficulty=[\n",
      "            -1,\n",
      "        ],\n",
      "        filter_by_min_points=dict(Car=5, Cyclist=10, Pedestrian=10)),\n",
      "    rate=1.0,\n",
      "    sample_groups=dict(Car=12, Cyclist=6, Pedestrian=6))\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='Det3DVisualizationHook'))\n",
      "default_scope = 'mmdet3d'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "evaluation = dict(interval=20)\n",
      "ida_aug_conf = dict(\n",
      "    H=370,\n",
      "    W=1224,\n",
      "    bot_pct_lim=(\n",
      "        0.0,\n",
      "        0.0,\n",
      "    ),\n",
      "    final_dim=(\n",
      "        320,\n",
      "        960,\n",
      "    ),\n",
      "    rand_flip=True,\n",
      "    resize_lim=(\n",
      "        0.47,\n",
      "        0.625,\n",
      "    ),\n",
      "    rot_lim=(\n",
      "        0.0,\n",
      "        0.0,\n",
      "    ))\n",
      "img_norm_cfg = dict(\n",
      "    mean=[\n",
      "        103.53,\n",
      "        116.28,\n",
      "        123.675,\n",
      "    ],\n",
      "    std=[\n",
      "        57.375,\n",
      "        57.12,\n",
      "        58.395,\n",
      "    ],\n",
      "    to_rgb=False)\n",
      "input_modality = dict(use_camera=True, use_lidar=True)\n",
      "load_from = 'models/nuim_r50.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "lr = 0.0018\n",
      "metainfo = dict(classes=[\n",
      "    'Pedestrian',\n",
      "    'Cyclist',\n",
      "    'Car',\n",
      "])\n",
      "model = dict(\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=False,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='Det3DDataPreprocessor'),\n",
      "    img_backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=-1,\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet',\n",
      "        with_cp=True),\n",
      "    img_neck=dict(\n",
      "        in_channels=[\n",
      "            1024,\n",
      "            2048,\n",
      "        ], num_outs=2, out_channels=256, type='CPFPN'),\n",
      "    pts_backbone=dict(\n",
      "        conv_cfg=dict(bias=False, type='Conv2d'),\n",
      "        in_channels=256,\n",
      "        layer_nums=[\n",
      "            5,\n",
      "            5,\n",
      "        ],\n",
      "        layer_strides=[\n",
      "            1,\n",
      "            2,\n",
      "        ],\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.01, type='BN'),\n",
      "        out_channels=[\n",
      "            128,\n",
      "            256,\n",
      "        ],\n",
      "        type='SECOND'),\n",
      "    pts_bbox_head=dict(\n",
      "        bbox_coder=dict(\n",
      "            max_num=300,\n",
      "            num_classes=3,\n",
      "            pc_range=[\n",
      "                0,\n",
      "                -40,\n",
      "                -3,\n",
      "                70.4,\n",
      "                40,\n",
      "                1,\n",
      "            ],\n",
      "            post_center_range=[\n",
      "                -10.0,\n",
      "                -50.0,\n",
      "                -4.0,\n",
      "                80.0,\n",
      "                50.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            type='MultiTaskBBoxCoder',\n",
      "            voxel_size=[\n",
      "                0.1,\n",
      "                0.1,\n",
      "                0.1,\n",
      "            ]),\n",
      "        common_heads=dict(\n",
      "            center=(\n",
      "                2,\n",
      "                2,\n",
      "            ), dim=(\n",
      "                3,\n",
      "                2,\n",
      "            ), height=(\n",
      "                1,\n",
      "                2,\n",
      "            ), rot=(\n",
      "                2,\n",
      "                2,\n",
      "            )),\n",
      "        downsample_scale=8,\n",
      "        hidden_dim=256,\n",
      "        in_channels=512,\n",
      "        loss_bbox=dict(\n",
      "            loss_weight=0.25, reduction='mean', type='mmdet.L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            alpha=0.25,\n",
      "            gamma=2,\n",
      "            loss_weight=2.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.FocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_heatmap=dict(\n",
      "            loss_weight=1.0, reduction='mean', type='mmdet.GaussianFocalLoss'),\n",
      "        separate_head=dict(\n",
      "            final_kernel=1, init_bias=-2.19, type='SeparateTaskHead'),\n",
      "        tasks=[\n",
      "            dict(class_names=[\n",
      "                'Pedestrian',\n",
      "                'Cyclist',\n",
      "                'Car',\n",
      "            ], num_class=10),\n",
      "        ],\n",
      "        transformer=dict(\n",
      "            decoder=dict(\n",
      "                num_layers=6,\n",
      "                return_intermediate=True,\n",
      "                transformerlayers=dict(\n",
      "                    attn_cfgs=[\n",
      "                        dict(\n",
      "                            dropout=0.1,\n",
      "                            embed_dims=256,\n",
      "                            num_heads=8,\n",
      "                            type='MultiheadAttention'),\n",
      "                        dict(\n",
      "                            dropout=0.1,\n",
      "                            embed_dims=256,\n",
      "                            num_heads=8,\n",
      "                            type='PETRMultiheadFlashAttention'),\n",
      "                    ],\n",
      "                    feedforward_channels=1024,\n",
      "                    ffn_cfgs=dict(\n",
      "                        act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                        embed_dims=256,\n",
      "                        feedforward_channels=1024,\n",
      "                        ffn_drop=0.0,\n",
      "                        num_fcs=2,\n",
      "                        type='FFN'),\n",
      "                    operation_order=(\n",
      "                        'self_attn',\n",
      "                        'norm',\n",
      "                        'cross_attn',\n",
      "                        'norm',\n",
      "                        'ffn',\n",
      "                        'norm',\n",
      "                    ),\n",
      "                    type='PETRTransformerDecoderLayer',\n",
      "                    with_cp=False),\n",
      "                type='PETRTransformerDecoder'),\n",
      "            type='CmtTransformer'),\n",
      "        type='CmtHead'),\n",
      "    pts_middle_encoder=dict(\n",
      "        block_type='basicblock',\n",
      "        encoder_channels=(\n",
      "            (\n",
      "                16,\n",
      "                16,\n",
      "                32,\n",
      "            ),\n",
      "            (\n",
      "                32,\n",
      "                32,\n",
      "                64,\n",
      "            ),\n",
      "            (\n",
      "                64,\n",
      "                64,\n",
      "                128,\n",
      "            ),\n",
      "            (\n",
      "                128,\n",
      "                128,\n",
      "            ),\n",
      "        ),\n",
      "        encoder_paddings=(\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "                1,\n",
      "            ),\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "                1,\n",
      "            ),\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "                [\n",
      "                    0,\n",
      "                    1,\n",
      "                    1,\n",
      "                ],\n",
      "            ),\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "            ),\n",
      "        ),\n",
      "        in_channels=4,\n",
      "        order=(\n",
      "            'conv',\n",
      "            'norm',\n",
      "            'act',\n",
      "        ),\n",
      "        output_channels=128,\n",
      "        sparse_shape=[\n",
      "            41,\n",
      "            800,\n",
      "            800,\n",
      "        ],\n",
      "        type='SparseEncoder'),\n",
      "    pts_neck=dict(\n",
      "        in_channels=[\n",
      "            128,\n",
      "            256,\n",
      "        ],\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.01, type='BN'),\n",
      "        out_channels=[\n",
      "            256,\n",
      "            256,\n",
      "        ],\n",
      "        type='SECONDFPN',\n",
      "        upsample_cfg=dict(bias=False, type='deconv'),\n",
      "        upsample_strides=[\n",
      "            1,\n",
      "            2,\n",
      "        ],\n",
      "        use_conv_for_no_stride=True),\n",
      "    pts_voxel_encoder=dict(num_features=4, type='HardSimpleVFE'),\n",
      "    pts_voxel_layer=dict(\n",
      "        max_num_points=10,\n",
      "        max_voxels=(\n",
      "            120000,\n",
      "            160000,\n",
      "        ),\n",
      "        num_point_features=4,\n",
      "        point_cloud_range=[\n",
      "            0,\n",
      "            -40,\n",
      "            -3,\n",
      "            70.4,\n",
      "            40,\n",
      "            1,\n",
      "        ],\n",
      "        voxel_size=[\n",
      "            0.1,\n",
      "            0.1,\n",
      "            0.1,\n",
      "        ]),\n",
      "    test_cfg=dict(\n",
      "        pts=dict(\n",
      "            dataset='kitti',\n",
      "            grid_size=[\n",
      "                800,\n",
      "                800,\n",
      "                40,\n",
      "            ],\n",
      "            max_num=200,\n",
      "            nms_thr=0.2,\n",
      "            nms_type=None,\n",
      "            out_size_factor=8,\n",
      "            pc_range=[\n",
      "                0,\n",
      "                -40,\n",
      "                -3,\n",
      "                70.4,\n",
      "                40,\n",
      "                1,\n",
      "            ],\n",
      "            use_rotate_nms=True,\n",
      "            voxel_size=[\n",
      "                0.1,\n",
      "                0.1,\n",
      "                0.1,\n",
      "            ])),\n",
      "    train_cfg=dict(\n",
      "        pts=dict(\n",
      "            assigner=dict(\n",
      "                cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
      "                code_weights=[\n",
      "                    2.0,\n",
      "                    2.0,\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                ],\n",
      "                iou_cost=dict(type='IoUCost', weight=0.0),\n",
      "                pc_range=[\n",
      "                    0,\n",
      "                    -40,\n",
      "                    -3,\n",
      "                    70.4,\n",
      "                    40,\n",
      "                    1,\n",
      "                ],\n",
      "                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),\n",
      "                type='HungarianAssigner3D'),\n",
      "            code_weights=[\n",
      "                2.0,\n",
      "                2.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            dataset='kitti',\n",
      "            gaussian_overlap=0.1,\n",
      "            grid_size=[\n",
      "                800,\n",
      "                800,\n",
      "                40,\n",
      "            ],\n",
      "            min_radius=2,\n",
      "            out_size_factor=8,\n",
      "            point_cloud_range=[\n",
      "                0,\n",
      "                -40,\n",
      "                -3,\n",
      "                70.4,\n",
      "                40,\n",
      "                1,\n",
      "            ],\n",
      "            pos_weight=-1,\n",
      "            voxel_size=[\n",
      "                0.1,\n",
      "                0.1,\n",
      "                0.1,\n",
      "            ])),\n",
      "    type='CmtDetector',\n",
      "    use_grid_mask=True)\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=10, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.95,\n",
      "            0.99,\n",
      "        ), lr=0.0018, type='AdamW', weight_decay=0.01),\n",
      "    type='OptimWrapper')\n",
      "out_size_factor = 8\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        T_max=16,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=16,\n",
      "        eta_min=0.018,\n",
      "        type='CosineAnnealingLR'),\n",
      "    dict(\n",
      "        T_max=24,\n",
      "        begin=16,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=40,\n",
      "        eta_min=1.8e-07,\n",
      "        type='CosineAnnealingLR'),\n",
      "    dict(\n",
      "        T_max=16,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=16,\n",
      "        eta_min=0.8947368421052632,\n",
      "        type='CosineAnnealingMomentum'),\n",
      "    dict(\n",
      "        T_max=24,\n",
      "        begin=16,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=40,\n",
      "        eta_min=1,\n",
      "        type='CosineAnnealingMomentum'),\n",
      "]\n",
      "point_cloud_range = [\n",
      "    0,\n",
      "    -40,\n",
      "    -3,\n",
      "    70.4,\n",
      "    40,\n",
      "    1,\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict()\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='kitti_infos_val.pkl',\n",
      "        backend_args=None,\n",
      "        box_type_3d='LiDAR',\n",
      "        data_prefix=dict(\n",
      "            img='training/image_2', pts='training/velodyne_reduced'),\n",
      "        data_root='data/kitti/',\n",
      "        metainfo=dict(classes=[\n",
      "            'Pedestrian',\n",
      "            'Cyclist',\n",
      "            'Car',\n",
      "        ]),\n",
      "        modality=dict(use_camera=True, use_lidar=True),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                coord_type='LIDAR',\n",
      "                load_dim=4,\n",
      "                type='LoadPointsFromFile',\n",
      "                use_dim=4),\n",
      "            dict(\n",
      "                backend_args=None,\n",
      "                color_type='color',\n",
      "                to_float32=True,\n",
      "                type='LoadMultiViewImageFromFilesKitti'),\n",
      "            dict(\n",
      "                point_cloud_range=[\n",
      "                    0,\n",
      "                    -40,\n",
      "                    -3,\n",
      "                    70.4,\n",
      "                    40,\n",
      "                    1,\n",
      "                ],\n",
      "                type='PointsRangeFilter'),\n",
      "            dict(\n",
      "                flip=False,\n",
      "                img_scale=(\n",
      "                    1333,\n",
      "                    800,\n",
      "                ),\n",
      "                pts_scale_ratio=1,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        rot_range=[\n",
      "                            0,\n",
      "                            0,\n",
      "                        ],\n",
      "                        scale_ratio_range=[\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                        ],\n",
      "                        translation_std=[\n",
      "                            0,\n",
      "                            0,\n",
      "                            0,\n",
      "                        ],\n",
      "                        type='GlobalRotScaleTrans'),\n",
      "                    dict(\n",
      "                        data_aug_conf=dict(\n",
      "                            H=370,\n",
      "                            W=1224,\n",
      "                            bot_pct_lim=(\n",
      "                                0.0,\n",
      "                                0.0,\n",
      "                            ),\n",
      "                            final_dim=(\n",
      "                                320,\n",
      "                                960,\n",
      "                            ),\n",
      "                            rand_flip=True,\n",
      "                            resize_lim=(\n",
      "                                0.47,\n",
      "                                0.625,\n",
      "                            ),\n",
      "                            rot_lim=(\n",
      "                                0.0,\n",
      "                                0.0,\n",
      "                            )),\n",
      "                        training=False,\n",
      "                        type='ResizeCropFlipImage'),\n",
      "                    dict(\n",
      "                        mean=[\n",
      "                            103.53,\n",
      "                            116.28,\n",
      "                            123.675,\n",
      "                        ],\n",
      "                        std=[\n",
      "                            57.375,\n",
      "                            57.12,\n",
      "                            58.395,\n",
      "                        ],\n",
      "                        to_rgb=False,\n",
      "                        type='NormalizeMultiviewImage'),\n",
      "                    dict(size_divisor=32, type='PadMultiViewImage'),\n",
      "                ],\n",
      "                type='MultiScaleFlipAug3D'),\n",
      "            dict(keys=[\n",
      "                'points',\n",
      "                'img',\n",
      "            ], type='Pack3DDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='KittiDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/kitti/kitti_infos_val.pkl',\n",
      "    backend_args=None,\n",
      "    metric='bbox',\n",
      "    type='KittiMetric')\n",
      "test_pipeline = [\n",
      "    dict(coord_type='LIDAR', load_dim=4, type='LoadPointsFromFile', use_dim=4),\n",
      "    dict(\n",
      "        backend_args=None,\n",
      "        color_type='color',\n",
      "        to_float32=True,\n",
      "        type='LoadMultiViewImageFromFilesKitti'),\n",
      "    dict(\n",
      "        point_cloud_range=[\n",
      "            0,\n",
      "            -40,\n",
      "            -3,\n",
      "            70.4,\n",
      "            40,\n",
      "            1,\n",
      "        ],\n",
      "        type='PointsRangeFilter'),\n",
      "    dict(\n",
      "        flip=False,\n",
      "        img_scale=(\n",
      "            1333,\n",
      "            800,\n",
      "        ),\n",
      "        pts_scale_ratio=1,\n",
      "        transforms=[\n",
      "            dict(\n",
      "                rot_range=[\n",
      "                    0,\n",
      "                    0,\n",
      "                ],\n",
      "                scale_ratio_range=[\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                ],\n",
      "                translation_std=[\n",
      "                    0,\n",
      "                    0,\n",
      "                    0,\n",
      "                ],\n",
      "                type='GlobalRotScaleTrans'),\n",
      "            dict(\n",
      "                data_aug_conf=dict(\n",
      "                    H=370,\n",
      "                    W=1224,\n",
      "                    bot_pct_lim=(\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ),\n",
      "                    final_dim=(\n",
      "                        320,\n",
      "                        960,\n",
      "                    ),\n",
      "                    rand_flip=True,\n",
      "                    resize_lim=(\n",
      "                        0.47,\n",
      "                        0.625,\n",
      "                    ),\n",
      "                    rot_lim=(\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    )),\n",
      "                training=False,\n",
      "                type='ResizeCropFlipImage'),\n",
      "            dict(\n",
      "                mean=[\n",
      "                    103.53,\n",
      "                    116.28,\n",
      "                    123.675,\n",
      "                ],\n",
      "                std=[\n",
      "                    57.375,\n",
      "                    57.12,\n",
      "                    58.395,\n",
      "                ],\n",
      "                to_rgb=False,\n",
      "                type='NormalizeMultiviewImage'),\n",
      "            dict(size_divisor=32, type='PadMultiViewImage'),\n",
      "        ],\n",
      "        type='MultiScaleFlipAug3D'),\n",
      "    dict(keys=[\n",
      "        'points',\n",
      "        'img',\n",
      "    ], type='Pack3DDetInputs'),\n",
      "]\n",
      "train_cfg = dict(by_epoch=True, max_epochs=40, val_interval=5)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file='kitti_infos_train.pkl',\n",
      "            backend_args=None,\n",
      "            box_type_3d='LiDAR',\n",
      "            data_prefix=dict(\n",
      "                img='training/image_2', pts='training/velodyne_reduced'),\n",
      "            data_root='data/kitti/',\n",
      "            metainfo=dict(classes=[\n",
      "                'Pedestrian',\n",
      "                'Cyclist',\n",
      "                'Car',\n",
      "            ]),\n",
      "            modality=dict(use_camera=True, use_lidar=True),\n",
      "            pipeline=[\n",
      "                dict(\n",
      "                    coord_type='LIDAR',\n",
      "                    load_dim=4,\n",
      "                    type='LoadPointsFromFile',\n",
      "                    use_dim=4),\n",
      "                dict(\n",
      "                    backend_args=None,\n",
      "                    color_type='color',\n",
      "                    to_float32=True,\n",
      "                    type='LoadMultiViewImageFromFilesKitti'),\n",
      "                dict(\n",
      "                    type='LoadAnnotations3D',\n",
      "                    with_bbox_3d=True,\n",
      "                    with_label_3d=True),\n",
      "                dict(\n",
      "                    db_sampler=dict(\n",
      "                        backend_args=None,\n",
      "                        classes=[\n",
      "                            'Pedestrian',\n",
      "                            'Cyclist',\n",
      "                            'Car',\n",
      "                        ],\n",
      "                        data_root='data/kitti/',\n",
      "                        info_path='data/kitti/kitti_dbinfos_train.pkl',\n",
      "                        points_loader=dict(\n",
      "                            backend_args=None,\n",
      "                            coord_type='LIDAR',\n",
      "                            load_dim=4,\n",
      "                            type='LoadPointsFromFile',\n",
      "                            use_dim=4),\n",
      "                        prepare=dict(\n",
      "                            filter_by_difficulty=[\n",
      "                                -1,\n",
      "                            ],\n",
      "                            filter_by_min_points=dict(\n",
      "                                Car=5, Cyclist=10, Pedestrian=10)),\n",
      "                        rate=1.0,\n",
      "                        sample_groups=dict(Car=12, Cyclist=6, Pedestrian=6)),\n",
      "                    type='ObjectSample'),\n",
      "                dict(\n",
      "                    rot_range=[\n",
      "                        -0.78539816,\n",
      "                        0.78539816,\n",
      "                    ],\n",
      "                    scale_ratio_range=[\n",
      "                        0.9,\n",
      "                        1.1,\n",
      "                    ],\n",
      "                    translation_std=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                    ],\n",
      "                    type='GlobalRotScaleTransAll'),\n",
      "                dict(\n",
      "                    flip_ratio_bev_horizontal=0.5,\n",
      "                    sync_2d=False,\n",
      "                    type='CustomRandomFlip3D'),\n",
      "                dict(\n",
      "                    point_cloud_range=[\n",
      "                        0,\n",
      "                        -40,\n",
      "                        -3,\n",
      "                        70.4,\n",
      "                        40,\n",
      "                        1,\n",
      "                    ],\n",
      "                    type='PointsRangeFilter'),\n",
      "                dict(\n",
      "                    point_cloud_range=[\n",
      "                        0,\n",
      "                        -40,\n",
      "                        -3,\n",
      "                        70.4,\n",
      "                        40,\n",
      "                        1,\n",
      "                    ],\n",
      "                    type='ObjectRangeFilter'),\n",
      "                dict(\n",
      "                    classes=[\n",
      "                        'Pedestrian',\n",
      "                        'Cyclist',\n",
      "                        'Car',\n",
      "                    ],\n",
      "                    type='ObjectNameFilter'),\n",
      "                dict(type='PointShuffle'),\n",
      "                dict(\n",
      "                    data_aug_conf=dict(\n",
      "                        H=370,\n",
      "                        W=1224,\n",
      "                        bot_pct_lim=(\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                        ),\n",
      "                        final_dim=(\n",
      "                            320,\n",
      "                            960,\n",
      "                        ),\n",
      "                        rand_flip=True,\n",
      "                        resize_lim=(\n",
      "                            0.47,\n",
      "                            0.625,\n",
      "                        ),\n",
      "                        rot_lim=(\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                        )),\n",
      "                    training=True,\n",
      "                    type='ResizeCropFlipImage'),\n",
      "                dict(\n",
      "                    mean=[\n",
      "                        103.53,\n",
      "                        116.28,\n",
      "                        123.675,\n",
      "                    ],\n",
      "                    std=[\n",
      "                        57.375,\n",
      "                        57.12,\n",
      "                        58.395,\n",
      "                    ],\n",
      "                    to_rgb=False,\n",
      "                    type='NormalizeMultiviewImage'),\n",
      "                dict(size_divisor=32, type='PadMultiViewImage'),\n",
      "                dict(\n",
      "                    keys=[\n",
      "                        'points',\n",
      "                        'img',\n",
      "                        'gt_bboxes_3d',\n",
      "                        'gt_labels_3d',\n",
      "                    ],\n",
      "                    meta_keys=(\n",
      "                        'filename',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'lidar2img',\n",
      "                        'depth2img',\n",
      "                        'cam2img',\n",
      "                        'pad_shape',\n",
      "                        'scale_factor',\n",
      "                        'flip',\n",
      "                        'pcd_horizontal_flip',\n",
      "                        'pcd_vertical_flip',\n",
      "                        'box_mode_3d',\n",
      "                        'box_type_3d',\n",
      "                        'img_norm_cfg',\n",
      "                        'pcd_trans',\n",
      "                        'sample_idx',\n",
      "                        'pcd_scale_factor',\n",
      "                        'pcd_rotation',\n",
      "                        'pts_filename',\n",
      "                        'transformation_3d_flow',\n",
      "                        'rot_degree',\n",
      "                        'gt_bboxes_3d',\n",
      "                        'gt_labels_3d',\n",
      "                    ),\n",
      "                    type='Pack3DDetInputs'),\n",
      "            ],\n",
      "            test_mode=False,\n",
      "            type='KittiDataset'),\n",
      "        type='CBGSDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(coord_type='LIDAR', load_dim=4, type='LoadPointsFromFile', use_dim=4),\n",
      "    dict(\n",
      "        backend_args=None,\n",
      "        color_type='color',\n",
      "        to_float32=True,\n",
      "        type='LoadMultiViewImageFromFilesKitti'),\n",
      "    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),\n",
      "    dict(\n",
      "        db_sampler=dict(\n",
      "            backend_args=None,\n",
      "            classes=[\n",
      "                'Pedestrian',\n",
      "                'Cyclist',\n",
      "                'Car',\n",
      "            ],\n",
      "            data_root='data/kitti/',\n",
      "            info_path='data/kitti/kitti_dbinfos_train.pkl',\n",
      "            points_loader=dict(\n",
      "                backend_args=None,\n",
      "                coord_type='LIDAR',\n",
      "                load_dim=4,\n",
      "                type='LoadPointsFromFile',\n",
      "                use_dim=4),\n",
      "            prepare=dict(\n",
      "                filter_by_difficulty=[\n",
      "                    -1,\n",
      "                ],\n",
      "                filter_by_min_points=dict(Car=5, Cyclist=10, Pedestrian=10)),\n",
      "            rate=1.0,\n",
      "            sample_groups=dict(Car=12, Cyclist=6, Pedestrian=6)),\n",
      "        type='ObjectSample'),\n",
      "    dict(\n",
      "        rot_range=[\n",
      "            -0.78539816,\n",
      "            0.78539816,\n",
      "        ],\n",
      "        scale_ratio_range=[\n",
      "            0.9,\n",
      "            1.1,\n",
      "        ],\n",
      "        translation_std=[\n",
      "            0.5,\n",
      "            0.5,\n",
      "            0.5,\n",
      "        ],\n",
      "        type='GlobalRotScaleTransAll'),\n",
      "    dict(\n",
      "        flip_ratio_bev_horizontal=0.5,\n",
      "        sync_2d=False,\n",
      "        type='CustomRandomFlip3D'),\n",
      "    dict(\n",
      "        point_cloud_range=[\n",
      "            0,\n",
      "            -40,\n",
      "            -3,\n",
      "            70.4,\n",
      "            40,\n",
      "            1,\n",
      "        ],\n",
      "        type='PointsRangeFilter'),\n",
      "    dict(\n",
      "        point_cloud_range=[\n",
      "            0,\n",
      "            -40,\n",
      "            -3,\n",
      "            70.4,\n",
      "            40,\n",
      "            1,\n",
      "        ],\n",
      "        type='ObjectRangeFilter'),\n",
      "    dict(classes=[\n",
      "        'Pedestrian',\n",
      "        'Cyclist',\n",
      "        'Car',\n",
      "    ], type='ObjectNameFilter'),\n",
      "    dict(type='PointShuffle'),\n",
      "    dict(\n",
      "        data_aug_conf=dict(\n",
      "            H=370,\n",
      "            W=1224,\n",
      "            bot_pct_lim=(\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ),\n",
      "            final_dim=(\n",
      "                320,\n",
      "                960,\n",
      "            ),\n",
      "            rand_flip=True,\n",
      "            resize_lim=(\n",
      "                0.47,\n",
      "                0.625,\n",
      "            ),\n",
      "            rot_lim=(\n",
      "                0.0,\n",
      "                0.0,\n",
      "            )),\n",
      "        training=True,\n",
      "        type='ResizeCropFlipImage'),\n",
      "    dict(\n",
      "        mean=[\n",
      "            103.53,\n",
      "            116.28,\n",
      "            123.675,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.12,\n",
      "            58.395,\n",
      "        ],\n",
      "        to_rgb=False,\n",
      "        type='NormalizeMultiviewImage'),\n",
      "    dict(size_divisor=32, type='PadMultiViewImage'),\n",
      "    dict(\n",
      "        keys=[\n",
      "            'points',\n",
      "            'img',\n",
      "            'gt_bboxes_3d',\n",
      "            'gt_labels_3d',\n",
      "        ],\n",
      "        meta_keys=(\n",
      "            'filename',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'lidar2img',\n",
      "            'depth2img',\n",
      "            'cam2img',\n",
      "            'pad_shape',\n",
      "            'scale_factor',\n",
      "            'flip',\n",
      "            'pcd_horizontal_flip',\n",
      "            'pcd_vertical_flip',\n",
      "            'box_mode_3d',\n",
      "            'box_type_3d',\n",
      "            'img_norm_cfg',\n",
      "            'pcd_trans',\n",
      "            'sample_idx',\n",
      "            'pcd_scale_factor',\n",
      "            'pcd_rotation',\n",
      "            'pts_filename',\n",
      "            'transformation_3d_flow',\n",
      "            'rot_degree',\n",
      "            'gt_bboxes_3d',\n",
      "            'gt_labels_3d',\n",
      "        ),\n",
      "        type='Pack3DDetInputs'),\n",
      "]\n",
      "val_cfg = dict()\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='kitti_infos_val.pkl',\n",
      "        backend_args=None,\n",
      "        box_type_3d='LiDAR',\n",
      "        data_prefix=dict(\n",
      "            img='training/image_2', pts='training/velodyne_reduced'),\n",
      "        data_root='data/kitti/',\n",
      "        metainfo=dict(classes=[\n",
      "            'Pedestrian',\n",
      "            'Cyclist',\n",
      "            'Car',\n",
      "        ]),\n",
      "        modality=dict(use_camera=True, use_lidar=True),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                coord_type='LIDAR',\n",
      "                load_dim=4,\n",
      "                type='LoadPointsFromFile',\n",
      "                use_dim=4),\n",
      "            dict(\n",
      "                backend_args=None,\n",
      "                color_type='color',\n",
      "                to_float32=True,\n",
      "                type='LoadMultiViewImageFromFilesKitti'),\n",
      "            dict(\n",
      "                point_cloud_range=[\n",
      "                    0,\n",
      "                    -40,\n",
      "                    -3,\n",
      "                    70.4,\n",
      "                    40,\n",
      "                    1,\n",
      "                ],\n",
      "                type='PointsRangeFilter'),\n",
      "            dict(\n",
      "                flip=False,\n",
      "                img_scale=(\n",
      "                    1333,\n",
      "                    800,\n",
      "                ),\n",
      "                pts_scale_ratio=1,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        rot_range=[\n",
      "                            0,\n",
      "                            0,\n",
      "                        ],\n",
      "                        scale_ratio_range=[\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                        ],\n",
      "                        translation_std=[\n",
      "                            0,\n",
      "                            0,\n",
      "                            0,\n",
      "                        ],\n",
      "                        type='GlobalRotScaleTrans'),\n",
      "                    dict(\n",
      "                        data_aug_conf=dict(\n",
      "                            H=370,\n",
      "                            W=1224,\n",
      "                            bot_pct_lim=(\n",
      "                                0.0,\n",
      "                                0.0,\n",
      "                            ),\n",
      "                            final_dim=(\n",
      "                                320,\n",
      "                                960,\n",
      "                            ),\n",
      "                            rand_flip=True,\n",
      "                            resize_lim=(\n",
      "                                0.47,\n",
      "                                0.625,\n",
      "                            ),\n",
      "                            rot_lim=(\n",
      "                                0.0,\n",
      "                                0.0,\n",
      "                            )),\n",
      "                        training=False,\n",
      "                        type='ResizeCropFlipImage'),\n",
      "                    dict(\n",
      "                        mean=[\n",
      "                            103.53,\n",
      "                            116.28,\n",
      "                            123.675,\n",
      "                        ],\n",
      "                        std=[\n",
      "                            57.375,\n",
      "                            57.12,\n",
      "                            58.395,\n",
      "                        ],\n",
      "                        to_rgb=False,\n",
      "                        type='NormalizeMultiviewImage'),\n",
      "                    dict(size_divisor=32, type='PadMultiViewImage'),\n",
      "                ],\n",
      "                type='MultiScaleFlipAug3D'),\n",
      "            dict(keys=[\n",
      "                'points',\n",
      "                'img',\n",
      "            ], type='Pack3DDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='KittiDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='data/kitti/kitti_infos_val.pkl',\n",
      "    backend_args=None,\n",
      "    metric='bbox',\n",
      "    type='KittiMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='Det3DLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "voxel_size = [\n",
      "    0.1,\n",
      "    0.1,\n",
      "    0.1,\n",
      "]\n",
      "work_dir = '/media/helloalone/新加卷/ubuntu_code/My_CMT/work_dirs'\n",
      "\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/helloalone/新加卷/ubuntu_anaconda_envs/python38/lib/python3.8/site-packages/mmdet/models/task_modules/builder.py:17: UserWarning: ``build_sampler`` would be deprecated soon, please use ``mmdet.registry.TASK_UTILS.build()`` \n",
      "  warnings.warn('``build_sampler`` would be deprecated soon, please use '\n",
      "/media/helloalone/新加卷/ubuntu_anaconda_envs/python38/lib/python3.8/site-packages/mmdet/models/task_modules/builder.py:39: UserWarning: ``build_assigner`` would be deprecated soon, please use ``mmdet.registry.TASK_UTILS.build()`` \n",
      "  warnings.warn('``build_assigner`` would be deprecated soon, please use '\n",
      "/media/helloalone/新加卷/ubuntu_anaconda_envs/python38/lib/python3.8/site-packages/mmdet/models/task_modules/builder.py:46: UserWarning: ``build_sampler`` would be deprecated soon, please use ``mmdet.registry.TASK_UTILS.build()`` \n",
      "  warnings.warn('``build_sampler`` would be deprecated soon, please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/19 13:20:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/19 13:20:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) Det3DVisualizationHook             \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) Det3DVisualizationHook             \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile('projects/configs/fusion/my_cmt_kitti.py')\n",
    "# cfg = Config.fromfile('../mmdetection3d/projects/BEVFusion/configs/my_bevfusion.py')\n",
    "cfg.work_dir = osp.abspath('./work_dirs')\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CmtDetector(\n",
       "  (data_preprocessor): Det3DDataPreprocessor()\n",
       "  (pts_voxel_encoder): HardSimpleVFE()\n",
       "  (pts_middle_encoder): SparseEncoder(\n",
       "    (conv_input): SparseSequential(\n",
       "      (0): SubMConv3d(4, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (encoder_layers): SparseSequential(\n",
       "      (encoder_layer1): SparseSequential(\n",
       "        (0): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SparseSequential(\n",
       "          (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer2): SparseSequential(\n",
       "        (0): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SparseSequential(\n",
       "          (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer3): SparseSequential(\n",
       "        (0): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SparseSequential(\n",
       "          (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer4): SparseSequential(\n",
       "        (0): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_out): SparseSequential(\n",
       "      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pts_backbone): SECOND(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
       "  (pts_neck): SECONDFPN(\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
       "  (pts_bbox_head): CmtHead(\n",
       "    (loss_cls): FocalLoss()\n",
       "    (loss_bbox): L1Loss()\n",
       "    (loss_heatmap): GaussianFocalLoss()\n",
       "    (shared_conv): ConvModule(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (transformer): CmtTransformer(\n",
       "      (decoder): PETRTransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x PETRTransformerDecoderLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): PETRMultiheadFlashAttention(\n",
       "                (attn): FlashMHA(\n",
       "                  (inner_attn): FlashAttention()\n",
       "                  (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "                (gamma2): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0-2): 3 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (reference_points): Embedding(900, 3)\n",
       "    (bev_embedding): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (rv_embedding): Sequential(\n",
       "      (0): Linear(in_features=192, out_features=1024, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    )\n",
       "    (task_heads): ModuleList(\n",
       "      (0): SeparateTaskHead(\n",
       "        (center): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 12, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "        (height): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 6, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "        (dim): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 18, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "        (rot): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 12, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "        (cls_logits): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 18, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Kaiming', 'layer': 'Conv1d'}\n",
       "    )\n",
       "  )\n",
       "  (img_backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (img_neck): CPFPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
       "  (grid_mask): GridMask()\n",
       "  (pts_voxel_layer): SPConvVoxelization(voxel_size=[0.1 0.1 0.1], point_cloud_range=[  0.  -40.   -3.   70.4  40.    1. ], max_num_points=10, max_voxels=(120000, 160000), num_point_features=4)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 2207 Pedestrian database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 14357 Car database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 734 Cyclist database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 1297 Van database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 488 Truck database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 224 Tram database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 337 Misc database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 56 Person_sitting database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - After filter database:\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 2019 Pedestrian database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 10520 Car database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 564 Cyclist database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 826 Van database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 321 Truck database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 199 Tram database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 259 Misc database infos in DataBaseSampler\n",
      "03/19 13:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load 53 Person_sitting database infos in DataBaseSampler\n",
      "03/19 13:20:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - ------------------------------\n",
      "03/19 13:20:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The length of training dataset: 3712\n",
      "03/19 13:20:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The number of instances per category in the dataset:\n",
      "+------------+--------+\n",
      "| category   | number |\n",
      "+------------+--------+\n",
      "| Pedestrian | 2207   |\n",
      "| Cyclist    | 734    |\n",
      "| Car        | 14357  |\n",
      "+------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/helloalone/新加卷/ubuntu_code/My_CMT/projects/mmdet3d_plugin/models/utils/grid_mask.py:114: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400400184/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  mask = torch.from_numpy(mask).float().cuda()\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    data_batch = next(iter(runner.train_dataloader))\n",
    "    data_batch = runner.model.data_preprocessor(data_batch, training=False)\n",
    "    batch_inputs_dict = data_batch['inputs']\n",
    "    batch_data_samples = data_batch['data_samples']\n",
    "    imgs = batch_inputs_dict.get('imgs', None)\n",
    "    points = batch_inputs_dict.get('points', None)\n",
    "    img_metas = [item.metainfo for item in batch_data_samples]\n",
    "\n",
    "    img_feats = runner.model.extract_img_feat(imgs, img_metas)\n",
    "    voxels, num_points, coors = runner.model.voxelize(points)\n",
    "    voxel_features = runner.model.pts_voxel_encoder(voxels, num_points, coors)\n",
    "    batch_size = coors[-1, 0] + 1\n",
    "    x1 = runner.model.pts_middle_encoder(voxel_features, coors, batch_size)\n",
    "    x2 = runner.model.pts_backbone(x1)\n",
    "    if runner.model.with_pts_neck:\n",
    "        x3 = runner.model.pts_neck(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 256, 20, 60]), torch.Size([4, 256, 10, 30]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_feats[0].shape, img_feats[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48604, 4]),\n",
       " torch.Size([4, 256, 100, 100]),\n",
       " torch.Size([4, 128, 100, 100]),\n",
       " torch.Size([4, 256, 50, 50]),\n",
       " torch.Size([4, 512, 100, 100]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxel_features.shape, x1.shape, x2[0].shape, x2[1].shape, x3[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/helloalone/新加卷/ubuntu_anaconda_envs/python38/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/media/helloalone/新加卷/ubuntu_anaconda_envs/python38/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400400184/work/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# 训练过程\n",
    "for data_batch in runner.train_dataloader:\n",
    "    data_batch = runner.model.data_preprocessor(data_batch, training=True)\n",
    "    if isinstance(data_batch, dict):\n",
    "        losses = runner.model(**data_batch, mode='loss')\n",
    "    elif isinstance(data_batch, (list, tuple)):\n",
    "        losses = runner.model(*data_batch, mode='loss')\n",
    "    else:\n",
    "        raise TypeError()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_cls': tensor(4.5400, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'loss_bbox': tensor(4.8334, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd0.loss_cls': tensor(13.8242, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd0.loss_bbox': tensor(4.6958, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd1.loss_cls': tensor(7.4776, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd1.loss_bbox': tensor(4.7611, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd2.loss_cls': tensor(7.6146, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd2.loss_bbox': tensor(4.0996, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd3.loss_cls': tensor(6.0241, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd3.loss_bbox': tensor(5.0156, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd4.loss_cls': tensor(10.3131, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd4.loss_bbox': tensor(4.7757, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'dn_loss_cls': tensor(2.3941, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'dn_loss_bbox': tensor(5.8194, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd0.dn_loss_cls': tensor(7.2558, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd0.dn_loss_bbox': tensor(7.4565, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd1.dn_loss_cls': tensor(3.9161, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd1.dn_loss_bbox': tensor(3.9412, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd2.dn_loss_cls': tensor(4.1070, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd2.dn_loss_bbox': tensor(5.3388, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd3.dn_loss_cls': tensor(3.0572, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd3.dn_loss_bbox': tensor(5.7183, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd4.dn_loss_cls': tensor(5.2525, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'd4.dn_loss_bbox': tensor(6.7450, device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch['inputs'], data_batch['data_samples'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CmtDetector(\n",
       "  (data_preprocessor): Det3DDataPreprocessor()\n",
       "  (pts_voxel_encoder): HardSimpleVFE()\n",
       "  (pts_middle_encoder): SparseEncoder(\n",
       "    (conv_input): SparseSequential(\n",
       "      (0): SubMConv3d(4, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (encoder_layers): SparseSequential(\n",
       "      (encoder_layer1): SparseSequential(\n",
       "        (0): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SparseSequential(\n",
       "          (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer2): SparseSequential(\n",
       "        (0): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SparseSequential(\n",
       "          (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer3): SparseSequential(\n",
       "        (0): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SparseSequential(\n",
       "          (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer4): SparseSequential(\n",
       "        (0): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SparseBasicBlock(\n",
       "          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "          (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_out): SparseSequential(\n",
       "      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
       "      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pts_backbone): SECOND(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}\n",
       "  (pts_neck): SECONDFPN(\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]\n",
       "  (pts_bbox_head): CmtHead(\n",
       "    (loss_cls): FocalLoss()\n",
       "    (loss_bbox): L1Loss()\n",
       "    (loss_heatmap): GaussianFocalLoss()\n",
       "    (shared_conv): ConvModule(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (transformer): CmtTransformer(\n",
       "      (decoder): PETRTransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x PETRTransformerDecoderLayer(\n",
       "            (attentions): ModuleList(\n",
       "              (0): MultiheadAttention(\n",
       "                (attn): MultiheadAttention(\n",
       "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): PETRMultiheadFlashAttention(\n",
       "                (attn): FlashMHA(\n",
       "                  (inner_attn): FlashAttention()\n",
       "                  (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ffns): ModuleList(\n",
       "              (0): FFN(\n",
       "                (layers): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (dropout_layer): Identity()\n",
       "                (gamma2): Identity()\n",
       "              )\n",
       "            )\n",
       "            (norms): ModuleList(\n",
       "              (0-2): 3 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (reference_points): Embedding(900, 3)\n",
       "    (bev_embedding): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (rv_embedding): Sequential(\n",
       "      (0): Linear(in_features=192, out_features=1024, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    )\n",
       "    (task_heads): ModuleList(\n",
       "      (0): SeparateTaskHead(\n",
       "        (center): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 12, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "        (height): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 6, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "        (dim): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 18, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "        (rot): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 12, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "        (cls_logits): Sequential(\n",
       "          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)\n",
       "          (1): GroupLayerNorm1d()\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(384, 18, kernel_size=(1,), stride=(1,), groups=6)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Kaiming', 'layer': 'Conv1d'}\n",
       "    )\n",
       "  )\n",
       "  (img_backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
       "  (img_neck): CPFPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
       "  (grid_mask): GridMask()\n",
       "  (pts_voxel_layer): SPConvVoxelization(voxel_size=[0.1 0.1 0.1], point_cloud_range=[  0.  -40.   -3.   70.4  40.    1. ], max_num_points=10, max_voxels=(120000, 160000), num_point_features=4)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/19 13:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - ------------------------------\n",
      "03/19 13:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The length of test dataset: 3769\n",
      "03/19 13:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The number of instances per category in the dataset:\n",
      "+------------+--------+\n",
      "| category   | number |\n",
      "+------------+--------+\n",
      "| Pedestrian | 2280   |\n",
      "| Cyclist    | 893    |\n",
      "| Car        | 14385  |\n",
      "+------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/helloalone/新加卷/ubuntu_code/mmdetection3d/mmdet3d/evaluation/functional/kitti_utils/eval.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def get_thresholds(scores: np.ndarray, num_gt, num_sample_pts=41):\n"
     ]
    }
   ],
   "source": [
    "# 验证过程\n",
    "for data_batch in runner.val_dataloader:\n",
    "    data_batch = runner.model.data_preprocessor(data_batch, training=False)\n",
    "    if isinstance(data_batch, dict):\n",
    "        outputs = runner.model(**data_batch, mode='predict')\n",
    "    elif isinstance(data_batch, (list, tuple)):\n",
    "        outputs = runner.model(**data_batch, mode='predict')\n",
    "    else:\n",
    "        raise TypeError()\n",
    "    runner.val_evaluator.process(data_samples=outputs, data_batch=data_batch)\n",
    "    break\n",
    "# with torch.no_grad():\n",
    "#     metrics = runner.val_evaluator.evaluate(len(runner.val_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Det3DDataSample(\n",
       "\n",
       "    META INFORMATION\n",
       "    pcd_vertical_flip: False\n",
       "    sample_idx: 0\n",
       "    num_views: 1\n",
       "    transformation_3d_flow: ['R', 'S', 'T']\n",
       "    pcd_rotation_angle: 0.0\n",
       "    lidar_path: 'data/kitti/training/velodyne_reduced/000001.bin'\n",
       "    num_pts_feats: 4\n",
       "    box_type_3d: <class 'mmdet3d.structures.bbox_3d.lidar_box3d.LiDARInstance3DBoxes'>\n",
       "    pcd_rotation: tensor([[1., 0., 0.],\n",
       "                [-0., 1., 0.],\n",
       "                [0., 0., 1.]])\n",
       "    box_mode_3d: <Box3DMode.LIDAR: 0>\n",
       "    pad_shape: (320, 960)\n",
       "    flip: False\n",
       "    cam2img: array([[[6.24032621e+02, 0.00000000e+00, 4.78186434e+02, 4.48572800e+01],\n",
       "                [0.00000000e+00, 6.24032621e+02, 1.49495355e+02, 2.16379100e-01],\n",
       "                [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.74588400e-03],\n",
       "                [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]])\n",
       "    lidar2cam: array([[[ 2.34773921e-04, -9.99944150e-01, -1.05634769e-02,\n",
       "                 -2.79681687e-03],\n",
       "                [ 1.04494076e-02,  1.05653545e-02, -9.99889612e-01,\n",
       "                 -7.51087889e-02],\n",
       "                [ 9.99945343e-01,  1.24365499e-04,  1.04513029e-02,\n",
       "                 -2.72132814e-01],\n",
       "                [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "                  1.00000000e+00]]])\n",
       "    img_path: 'data/kitti/training/image_2/000001.png'\n",
       "    img_shape: [(320, 960, 3)]\n",
       "    img_norm_cfg: \n",
       "        mean: array([103.53 , 116.28 , 123.675], dtype=float32)\n",
       "        std: array([57.375, 57.12 , 58.395], dtype=float32)\n",
       "        to_rgb: False\n",
       "    lidar2img: array([[[ 6.09695381e+02, -7.21421594e+02, -1.25125800e+00,\n",
       "                 -1.23041816e+02],\n",
       "                [ 1.80384194e+02,  7.64479865e+00, -7.19651502e+02,\n",
       "                 -1.01016689e+02],\n",
       "                [ 9.99945343e-01,  1.24365499e-04,  1.04513029e-02,\n",
       "                 -2.69386930e-01],\n",
       "                [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "                  1.00000000e+00]]])\n",
       "    batch_input_shape: (320, 960)\n",
       "    ori_shape: (375, 1242)\n",
       "    pcd_horizontal_flip: False\n",
       "    pcd_trans: array([0., 0., 0.])\n",
       "    pcd_scale_factor: 1.0\n",
       "\n",
       "    DATA FIELDS\n",
       "    pred_instances_3d: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "            bboxes_3d: LiDARInstance3DBoxes(\n",
       "                    tensor([[ 4.2628e-04,  3.5714e+01, -2.5089e-01,  ...,  1.1528e+00,\n",
       "                          9.7695e-01, -2.0000e+00],\n",
       "                        [ 4.2633e-04,  3.6024e+01, -2.5105e-01,  ...,  1.1527e+00,\n",
       "                          9.7687e-01, -1.9991e+00],\n",
       "                        [ 4.2632e-04,  3.5862e+01, -2.5097e-01,  ...,  1.1528e+00,\n",
       "                          9.7693e-01, -1.9998e+00],\n",
       "                        ...,\n",
       "                        [ 4.2463e-04, -3.9999e+01, -2.5629e-01,  ...,  1.1511e+00,\n",
       "                          9.8235e-01, -2.0373e+00],\n",
       "                        [ 4.2463e-04, -3.9999e+01, -2.5629e-01,  ...,  1.1511e+00,\n",
       "                          9.8235e-01, -2.0373e+00],\n",
       "                        [ 4.2463e-04, -3.9999e+01, -2.5629e-01,  ...,  1.1511e+00,\n",
       "                          9.8235e-01, -2.0373e+00]], grad_fn=<CloneBackward0>))\n",
       "            labels_3d: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
       "            scores_3d: tensor([0.6143, 0.6143, 0.6143, 0.6143, 0.6143, 0.6143, 0.6143, 0.6143, 0.6143,\n",
       "                        0.6143, 0.6143, 0.6143, 0.6143, 0.6143, 0.6143, 0.6143, 0.6143, 0.6143,\n",
       "                        0.6143, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142,\n",
       "                        0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142,\n",
       "                        0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142,\n",
       "                        0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142,\n",
       "                        0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142,\n",
       "                        0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142,\n",
       "                        0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142,\n",
       "                        0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142,\n",
       "                        0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142, 0.6142,\n",
       "                        0.6142, 0.6142, 0.6142, 0.6141, 0.6141, 0.6141, 0.6141, 0.6141, 0.6141,\n",
       "                        0.6141, 0.6140, 0.6140, 0.6140, 0.6140, 0.6139, 0.6139, 0.6138, 0.6138,\n",
       "                        0.6138, 0.6138, 0.6138, 0.6138, 0.6138, 0.6138, 0.6138, 0.6138, 0.6138,\n",
       "                        0.6138, 0.6138, 0.6137, 0.6137, 0.6137, 0.6137, 0.6137, 0.6137, 0.6137,\n",
       "                        0.6137, 0.6137, 0.6137, 0.6137, 0.6137, 0.6137, 0.6137, 0.6137, 0.6137,\n",
       "                        0.6137, 0.6137, 0.6137, 0.6137, 0.6136, 0.6136, 0.6136, 0.6136, 0.6136,\n",
       "                        0.6136, 0.6136, 0.6136, 0.6136, 0.6136, 0.6136, 0.6136, 0.6136, 0.6136,\n",
       "                        0.6136, 0.6136, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135,\n",
       "                        0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135,\n",
       "                        0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135, 0.6135,\n",
       "                        0.6135, 0.6135, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134, 0.6134,\n",
       "                        0.6134, 0.6134, 0.6134], grad_fn=<ToCopyBackward0>)\n",
       "        ) at 0x7fce09fc9370>\n",
       "    gt_pts_seg: <PointData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7fcdfde0c820>\n",
       "    gt_instances: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7fcdfde0ce80>\n",
       "    eval_ann_info: \n",
       "        gt_bboxes: array([[387.63, 181.54, 423.81, 203.12],\n",
       "                   [676.6 , 163.95, 688.98, 193.93]], dtype=float32)\n",
       "        gt_bboxes_labels: array([2, 1])\n",
       "        gt_bboxes_3d: LiDARInstance3DBoxes(\n",
       "                tensor([[ 5.8781e+01,  1.6560e+01, -1.6761e+00,  3.6900e+00,  1.8700e+00,\n",
       "                      1.6700e+00, -3.1408e+00],\n",
       "                    [ 4.6125e+01, -4.5721e+00, -9.6154e-01,  2.0200e+00,  6.0000e-01,\n",
       "                      1.8600e+00, -2.0796e-02]]))\n",
       "        gt_labels_3d: array([2, 1])\n",
       "        depths: array([58.49275 , 45.842747], dtype=float32)\n",
       "        centers_2d: array([[406.3916 , 192.03131],\n",
       "                   [682.7452 , 178.98672]], dtype=float32)\n",
       "        num_lidar_pts: array([ 9, 18])\n",
       "        difficulty: array([-1, -1])\n",
       "        truncated: array([0., 0.])\n",
       "        occluded: array([0, 3])\n",
       "        alpha: array([ 1.85, -1.65])\n",
       "        score: array([0., 0.])\n",
       "        index: array([1, 2])\n",
       "        group_id: array([1, 2])\n",
       "        instances: [{'bbox': [599.41, 156.4, 629.75, 189.25], 'bbox_label': 4, 'bbox_3d': [0.47, 1.49, 69.44, 12.34, 2.85, 2.63, -1.56], 'bbox_label_3d': 4, 'depth': 69.4427490234375, 'center_2d': [615.0646362304688, 173.52566528320312], 'num_lidar_pts': 71, 'difficulty': 1, 'truncated': 0.0, 'occluded': 0, 'alpha': -1.57, 'score': 0.0, 'index': 0, 'group_id': 0}, {'bbox': [387.63, 181.54, 423.81, 203.12], 'bbox_label': 2, 'bbox_3d': [-16.53, 2.39, 58.49, 3.69, 1.67, 1.87, 1.57], 'bbox_label_3d': 2, 'depth': 58.49274826049805, 'center_2d': [406.3916015625, 192.03131103515625], 'num_lidar_pts': 9, 'difficulty': -1, 'truncated': 0.0, 'occluded': 0, 'alpha': 1.85, 'score': 0.0, 'index': 1, 'group_id': 1}, {'bbox': [676.6, 163.95, 688.98, 193.93], 'bbox_label': 1, 'bbox_3d': [4.59, 1.32, 45.84, 2.02, 1.86, 0.6, -1.55], 'bbox_label_3d': 1, 'depth': 45.84274673461914, 'center_2d': [682.7451782226562, 178.98672485351562], 'num_lidar_pts': 18, 'difficulty': -1, 'truncated': 0.0, 'occluded': 3, 'alpha': -1.65, 'score': 0.0, 'index': 2, 'group_id': 2}, {'bbox': [503.89, 169.71, 590.61, 190.13], 'bbox_label': -1, 'bbox_3d': [-1000.0, -1000.0, -1000.0, -1.0, -1.0, -1.0, -10.0], 'bbox_label_3d': -1, 'depth': -999.9972534179688, 'center_2d': [1331.055908203125, 894.033203125], 'num_lidar_pts': -1, 'difficulty': -1, 'truncated': -1.0, 'occluded': -1, 'alpha': -10.0, 'score': 0.0, 'index': -1, 'group_id': 3}, {'bbox': [511.35, 174.96, 527.81, 187.45], 'bbox_label': -1, 'bbox_3d': [-1000.0, -1000.0, -1000.0, -1.0, -1.0, -1.0, -10.0], 'bbox_label_3d': -1, 'depth': -999.9972534179688, 'center_2d': [1331.055908203125, 894.033203125], 'num_lidar_pts': -1, 'difficulty': -1, 'truncated': -1.0, 'occluded': -1, 'alpha': -10.0, 'score': 0.0, 'index': -1, 'group_id': 4}, {'bbox': [532.37, 176.35, 542.68, 185.27], 'bbox_label': -1, 'bbox_3d': [-1000.0, -1000.0, -1000.0, -1.0, -1.0, -1.0, -10.0], 'bbox_label_3d': -1, 'depth': -999.9972534179688, 'center_2d': [1331.055908203125, 894.033203125], 'num_lidar_pts': -1, 'difficulty': -1, 'truncated': -1.0, 'occluded': -1, 'alpha': -10.0, 'score': 0.0, 'index': -1, 'group_id': 5}, {'bbox': [559.62, 175.83, 575.4, 183.15], 'bbox_label': -1, 'bbox_3d': [-1000.0, -1000.0, -1000.0, -1.0, -1.0, -1.0, -10.0], 'bbox_label_3d': -1, 'depth': -999.9972534179688, 'center_2d': [1331.055908203125, 894.033203125], 'num_lidar_pts': -1, 'difficulty': -1, 'truncated': -1.0, 'occluded': -1, 'alpha': -10.0, 'score': 0.0, 'index': -1, 'group_id': 6}]\n",
       "    pred_instances: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7fce5da58280>\n",
       "    gt_instances_3d: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7fcdfde0ceb0>\n",
       ") at 0x7fcdfde0c760>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9588234424591064\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "num = 0\n",
    "with torch.no_grad():\n",
    "    for data_batch in runner.val_dataloader:\n",
    "        data_batch = runner.model.data_preprocessor(data_batch, training=False)\n",
    "        if isinstance(data_batch, dict):\n",
    "            outputs = runner.model(**data_batch, mode='predict')\n",
    "        elif isinstance(data_batch, (list, tuple)):\n",
    "            outputs = runner.model(**data_batch, mode='predict')\n",
    "        else:\n",
    "            raise TypeError()\n",
    "        num += 1\n",
    "        if num == 100:\n",
    "            break\n",
    "print(time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.595309019088745\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "with torch.no_grad():\n",
    "    data_batch_raw = next(iter(runner.val_dataloader))\n",
    "    for _ in range(100):\n",
    "        data_batch = runner.model.data_preprocessor(data_batch_raw, training=False)\n",
    "        if isinstance(data_batch, dict):\n",
    "            outputs = runner.model(**data_batch, mode='predict')\n",
    "        elif isinstance(data_batch, (list, tuple)):\n",
    "            outputs = runner.model(**data_batch, mode='predict')\n",
    "        else:\n",
    "            raise TypeError()\n",
    "print(time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.129737138748169 2.4780116081237793 2.382964849472046 0.0486757755279541\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    data_batch = next(iter(runner.val_dataloader))\n",
    "    data_batch = runner.model.data_preprocessor(data_batch, training=False)\n",
    "    batch_inputs_dict = data_batch['inputs']\n",
    "    batch_data_samples = data_batch['data_samples']\n",
    "    imgs = batch_inputs_dict.get('imgs', None)\n",
    "    points = batch_inputs_dict.get('points', None)\n",
    "    img_metas = [item.metainfo for item in batch_data_samples]\n",
    "\n",
    "    time_start = time.time()\n",
    "    for _ in range(100):\n",
    "        img_feats = runner.model.extract_img_feat(imgs, img_metas)\n",
    "    \n",
    "    midedle1 = time.time()\n",
    "    for _ in range(100):\n",
    "        pts_feats = runner.model.extract_pts_feat(points, img_feats, img_metas)\n",
    "\n",
    "    midedle2 = time.time()\n",
    "    for _ in range(100):\n",
    "        outs = runner.model.pts_bbox_head(pts_feats, img_feats, img_metas)\n",
    "\n",
    "    middle3 = time.time()\n",
    "    for _ in range(100):\n",
    "        bbox_list = runner.model.pts_bbox_head.get_bboxes(\n",
    "            outs, img_metas, rescale=False)\n",
    "        \n",
    "        # bbox_results = []\n",
    "        # for bboxes, scores, labels in bbox_list:\n",
    "        #     results = InstanceData()\n",
    "        #     results.bboxes_3d = bboxes.to('cpu')\n",
    "        #     results.scores_3d = scores.cpu()\n",
    "        #     results.labels_3d = labels.cpu()\n",
    "        #     bbox_results.append(results)\n",
    "        # detsamples = runner.model.add_pred_to_datasample(batch_data_samples,\n",
    "        #                                             data_instances_3d = bbox_results,\n",
    "        #                                             data_instances_2d = None)\n",
    "    end = time.time()\n",
    "    print(midedle1 - time_start, midedle2 - midedle1, middle3 - midedle2, end - middle3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
